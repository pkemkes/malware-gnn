import os
import json
import networkx as nx
import queue
import torch
import threading
from typing import List
from dataclasses import dataclass
from networkx.readwrite.json_graph import node_link_graph
from torch_geometric.utils import to_undirected
from torch_geometric.data import Data

from utilities.logger import Logger


@dataclass
class PreprocessorConfig:
    binary_classification: bool
    metapath_types: List[str]
    datadir: str
    thread_count: int
    logdir: str = os.path.join("output", "logs")
    logfile: str = "preproc_data.log"
    family_names: List[str] = None


class Preprocessor:

    def __init__(self, config: PreprocessorConfig):
        self.config = config
        self.rawdir = os.path.join(self.config.datadir, "raw")
        self.predir = os.path.join(self.config.datadir, "pre")
        self.processeddir = os.path.join(self.config.datadir, "processed")
        for path in [self.config.logdir, self.predir, self.processeddir]:
            if not os.path.exists(path):
                os.makedirs(path)
        self.logger = Logger(self.config.logdir, self.config.logfile, log_to_stdout=True)
        self.label_path = os.path.join(self.config.datadir, "labels.json")
        with open(self.label_path) as f:
            self.labels = json.load(f)
        self.sha_list_path = os.path.join(self.config.datadir, "sha_list.json")
        with open(self.sha_list_path) as f:
            self.sha_list = json.load(f)
        # we expect only the given families to occur and:
        # "other" if the sample in the subgraph is any other family
        # "" if the sample is known to be benign
        if not self.config.binary_classification:
            self.family_names = self.config.family_names + ["other", ""]
        self.raw_filenames = os.listdir(self.rawdir)
        self.max_lock = threading.Lock()
        self.min_lock = threading.Lock()
        self.q = None
        self.max_vals = None
        self.min_vals = None

    def preprocess(self):
        for mp in self.config.metapath_types:
            # define variables for max and min values for each meta path
            self.max_vals = None
            self.min_vals = None

            # start first step of preprocessing
            mp_raw_filenames = [fn for fn in self.raw_filenames if fn.startswith(f"{mp}-")]
            self.q = queue.Queue()
            for fn in mp_raw_filenames:
                self.q.put(fn)
            threads = []
            for i in range(self.config.thread_count):
                t = threading.Thread(target=self.convert_nxgraph_to_tensor, args=(i,))
                threads.append(t)
                t.start()
            self.q.join()
            for t in threads:
                t.join()

            # start second step of preprocessing
            # we can only normalize after we have seen all values, as we use min-max-normalization
            pre_filenames = os.listdir(self.predir)
            mp_pre_filenames = [fn for fn in pre_filenames if fn.startswith(f"pre-{mp}-")]
            self.q = queue.Queue()
            for fn in mp_pre_filenames:
                self.q.put(fn)
            threads = []
            for i in range(self.config.thread_count):
                t = threading.Thread(target=self.normalize, args=(i,))
                threads.append(t)
                t.start()
            self.q.join()
            for t in threads:
                t.join()

        self.logger.log("All done.")

    def convert_nxgraph_to_tensor(self, id_num: int):
        while not self.q.empty():
            filename = self.q.get()
            self.logger.log(f"T{id_num}: PRE -> {filename}")

            with open(os.path.join(self.rawdir, filename)) as f:
                nx_graph = nx.Graph(node_link_graph(json.load(f)))

            node_feature_list = []
            node_label_list = []

            root_sha = nx_graph.nodes[0].get("sha256")

            # for all samples in subgraph
            for node_id in nx_graph.nodes:
                node = nx_graph.nodes[node_id]

                sha = node.get("sha256")
                # we always need the verdict, but only need the family, we are doing multiclass classification
                verdict = node.get("verdict")
                if not self.config.binary_classification:
                    family = node.get("family")

                # create vectors for true labels
                if self.config.binary_classification:
                    label_vec = [1 if verdict == verdict else 0 for verdict in [0, 1, 2]]
                else:
                    label_vec = [1 if family_name == family else 0 for family_name in self.family_names[:-2]]
                node_label_list.append(label_vec)

                features = node.get("features")
                # prepend verdict (and family, if we are doing multiclass classification) to feature vector
                # but only if the sample is not the root sample (that is to be classified)
                # and if it is not in the set of other root samples in the training/validation/test datasets
                if sha == root_sha or sha in self.sha_list:
                    features = ([2] if self.config.binary_classification else [self.family_names.index(""), 2]) + features
                else:
                    features = ([verdict] if self.config.binary_classification else [self.family_names.index(family), verdict]) + features
                node_feature_list.append(features)

            # create torch datastrucures: edges, features and labels
            edge_index = to_undirected(torch.tensor(list(nx_graph.edges), dtype=torch.long).transpose(0, 1).contiguous())
            node_feature_index = torch.tensor(node_feature_list, dtype=torch.float)
            node_label_index = torch.tensor(node_label_list, dtype=torch.float)
            data = Data(node_feature_index, edge_index, y=node_label_index)
            del node_feature_list
            del node_label_list
            del nx_graph

            # compare values to other previously seen values and save the min and max for each column
            feature_max = node_feature_index.max(dim=0).values
            with self.max_lock:
                if self.max_vals is None:
                    self.max_vals = feature_max
                else:
                    self.max_vals = torch.where(feature_max > self.max_vals, feature_max, self.max_vals)
            feature_min = node_feature_index.min(dim=0).values
            with self.min_lock:
                if self.min_vals is None:
                    self.min_vals = feature_min
                else:
                    self.min_vals = torch.where(feature_min < self.min_vals, feature_min, self.min_vals)

            # save subgraph tensor to file
            torch.save(data, os.path.join(self.predir, f"pre-{filename.split('.json')[0]}.pt"))
            del edge_index
            del node_feature_index
            del node_label_index
            del data

            self.q.task_done()
        return

    def normalize(self, id_num: int):
        while not self.q.empty():
            filename = self.q.get()
            self.logger.log(f"T{id_num}: NORMALIZE -> {filename}")
            data = torch.load(os.path.join(self.predir, filename))
            # normalize feature vectors with the found minimum and maximum values for each feature column
            data.x = torch.where(self.max_vals - self.min_vals != 0,
                                 (data.x - self.min_vals) / (self.max_vals - self.min_vals), data.x - data.x)
            torch.save(data, os.path.join(self.processeddir, filename.split("pre-")[1]))
            self.q.task_done()
            del data
        return
